{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10153586,"sourceType":"datasetVersion","datasetId":6247782},{"sourceId":10155252,"sourceType":"datasetVersion","datasetId":6269842}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/minhloc29/Japanese-Characters-Recognition.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T07:33:18.238688Z","iopub.execute_input":"2024-12-12T07:33:18.239068Z","iopub.status.idle":"2024-12-12T07:33:21.982711Z","shell.execute_reply.started":"2024-12-12T07:33:18.239022Z","shell.execute_reply":"2024-12-12T07:33:21.981619Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Japanese-Characters-Recognition'...\nremote: Enumerating objects: 117, done.\u001b[K\nremote: Counting objects: 100% (117/117), done.\u001b[K\nremote: Compressing objects: 100% (110/110), done.\u001b[K\nremote: Total 117 (delta 49), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (117/117), 16.82 MiB | 12.94 MiB/s, done.\nResolving deltas: 100% (49/49), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd Japanese-Characters-Recognition\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nimport albumentations as A\nfrom data_loader import JapaneseDataset\nfrom unet import resnet_unet\nfrom losses_and_metrics import dice_coef, iou_score, bce_dice_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T07:35:23.926659Z","iopub.execute_input":"2024-12-12T07:35:23.927013Z","iopub.status.idle":"2024-12-12T07:35:23.965529Z","shell.execute_reply.started":"2024-12-12T07:35:23.926982Z","shell.execute_reply":"2024-12-12T07:35:23.964685Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Japanese-Characters-Recognition\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/train-images/train.csv\")\nlabels = train['labels'].to_list()\nroot_images_dir = \"/kaggle/input/train-images/train_images/train_images\"\nrelative_image_urls = os.listdir(root_images_dir)\nimage_urls = [os.path.join(root_images_dir, relative_image_url) for relative_image_url in relative_image_urls]\n\ncount_labels = [len(np.array(label.split()).reshape(-1, 5)) for label in labels]\nrange_counts = np.array([0, 50, 100, 150, 250, 300, 400, 500, 700])\nrange_labels = []\n\nfor count_char_label in count_labels:\n    for index, range_count in enumerate(range_counts[:-1]):\n        if count_char_label >= range_count and count_char_label <= range_counts[index + 1]:\n            range_labels.append(index)\n            break\n\ntrain_img_urls, val_img_urls, train_labels, val_labels = \\\n        train_test_split(image_urls, labels, test_size=0.1, stratify=range_labels, random_state=42)\n\ntrain_generator = JapaneseDataset(train_img_urls, train_labels, batch_size=8, augment=True, shuffle = True)\nevaluator_generator = JapaneseDataset(val_img_urls, val_labels, batch_size=8, augment=False, shuffle = False)\ntrain = train_generator.create_tf_dataset()\ntest = evaluator_generator.create_tf_dataset()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncsv = CSVLogger(\n    filename = \"/kaggle/working/Japanese-Characters-Recognition/models/training_log.csv\", append = True\n)\ncheckpoint = ModelCheckpoint(\n    filepath = \"model.keras\",\n    monitor = 'val_loss',\n    verbose = 1,\n    mode = 'min',\n    save_best_only = True,\n    save_weights_only = False,\n    save_freq = 'epoch',\n    initial_value_threshold = 0.9\n)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:27:07.684695Z","iopub.execute_input":"2024-12-11T07:27:07.685045Z","iopub.status.idle":"2024-12-11T07:27:07.690521Z","shell.execute_reply.started":"2024-12-11T07:27:07.685015Z","shell.execute_reply":"2024-12-11T07:27:07.689602Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\nfrom tensorflow.keras import mixed_precision\n\n# Set the mixed precision policy to 'mixed_bfloat16'\npolicy = mixed_precision.Policy('mixed_bfloat16')\nmixed_precision.set_global_policy(policy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:25:16.945247Z","iopub.execute_input":"2024-12-11T07:25:16.946121Z","iopub.status.idle":"2024-12-11T07:25:16.951262Z","shell.execute_reply.started":"2024-12-11T07:25:16.946086Z","shell.execute_reply":"2024-12-11T07:25:16.950174Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#Using 2 GPUs in Kaggle GPU T4x2 to accelerate training\n\nstrategy = tf.distribute.MirroredStrategy()\ntf.debugging.set_log_device_placement(True)\n\nwith strategy.scope():\n    model = resnet_unet(start_neurons = 16)\n    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss=bce_dice_loss, optimizer=optim, metrics=[iou_score, dice_coef])\n\nhistory = model.fit(train, epochs=10, validation_data=test, \n                   steps_per_epoch = 203, validation_steps=23, callbacks = [csv, checkpoint, reduce_lr])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T05:57:04.999054Z","iopub.execute_input":"2024-12-10T05:57:04.999426Z","iopub.status.idle":"2024-12-10T06:07:26.687777Z","shell.execute_reply.started":"2024-12-10T05:57:04.999389Z","shell.execute_reply":"2024-12-10T06:07:26.687049Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2024-12-10 05:57:52.457606: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_1068/cond/StatefulPartitionedCall/functional_5_1/dropout_12_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.7087 - iou_score: 0.5629 - loss: 0.6412\nEpoch 1: val_loss improved from 0.90000 to 0.50688, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 1s/step - dice_coef: 0.7090 - iou_score: 0.5632 - loss: 0.6403 - val_dice_coef: 0.7437 - val_iou_score: 0.5944 - val_loss: 0.5069 - learning_rate: 0.0100\nEpoch 2/10\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8248 - iou_score: 0.7028 - loss: 0.3229\nEpoch 2: val_loss improved from 0.50688 to 0.33093, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - dice_coef: 0.8248 - iou_score: 0.7028 - loss: 0.3229 - val_dice_coef: 0.8128 - val_iou_score: 0.6852 - val_loss: 0.3309 - learning_rate: 0.0100\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#This code is used for further training later\n\nstrategy = tf.distribute.MirroredStrategy()\ntf.debugging.set_log_device_placement(True)\n\nwith strategy.scope():\n    model = tf.keras.models.load_model('/kaggle/working/Japanese-Characters-Recognition/models/model.keras',\n                                   custom_objects = {\"dice_coef\": dice_coef, \n                                                     \"iou_score\": iou_score,\n                                                     \"bce_dice_loss\": bce_dice_loss})\n    \n    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss=bce_dice_loss, optimizer=optim, metrics=[iou_score, dice_coef])\n\nhistory = model.fit(train, epochs=5, validation_data=test, \n                   steps_per_epoch = 203, validation_steps=23, callbacks = [csv, checkpoint, reduce_lr])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:27:23.384991Z","iopub.execute_input":"2024-12-11T07:27:23.385742Z","iopub.status.idle":"2024-12-11T07:51:27.047042Z","shell.execute_reply.started":"2024-12-11T07:27:23.385705Z","shell.execute_reply":"2024-12-11T07:51:27.046227Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2024-12-11 07:28:13.528219: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_1068/cond/StatefulPartitionedCall/functional_3_1/dropout_6_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8863 - iou_score: 0.7963 - loss: 0.2102\nEpoch 1: val_loss improved from 0.90000 to 0.19891, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 1s/step - dice_coef: 0.8863 - iou_score: 0.7963 - loss: 0.2101 - val_dice_coef: 0.8878 - val_iou_score: 0.7990 - val_loss: 0.1989 - learning_rate: 0.0010\nEpoch 2/5\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8931 - iou_score: 0.8072 - loss: 0.1989\nEpoch 2: val_loss improved from 0.19891 to 0.17624, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 1s/step - dice_coef: 0.8931 - iou_score: 0.8072 - loss: 0.1989 - val_dice_coef: 0.9051 - val_iou_score: 0.8268 - val_loss: 0.1762 - learning_rate: 0.0010\nEpoch 3/5\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8968 - iou_score: 0.8133 - loss: 0.1906\nEpoch 3: val_loss improved from 0.17624 to 0.17290, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - dice_coef: 0.8968 - iou_score: 0.8133 - loss: 0.1907 - val_dice_coef: 0.9053 - val_iou_score: 0.8272 - val_loss: 0.1729 - learning_rate: 0.0010\nEpoch 4/5\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8991 - iou_score: 0.8171 - loss: 0.1871\nEpoch 4: val_loss improved from 0.17290 to 0.16909, saving model to model.keras\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - dice_coef: 0.8991 - iou_score: 0.8171 - loss: 0.1871 - val_dice_coef: 0.9067 - val_iou_score: 0.8296 - val_loss: 0.1691 - learning_rate: 0.0010\nEpoch 5/5\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - dice_coef: 0.8977 - iou_score: 0.8150 - loss: 0.1890\nEpoch 5: val_loss did not improve from 0.16909\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 1s/step - dice_coef: 0.8977 - iou_score: 0.8150 - loss: 0.1890 - val_dice_coef: 0.8940 - val_iou_score: 0.8086 - val_loss: 0.1903 - learning_rate: 0.0010\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
