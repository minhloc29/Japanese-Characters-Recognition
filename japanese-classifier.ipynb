{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10186234,"sourceType":"datasetVersion","datasetId":6292594}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/minhloc29/Japanese-Characters-Recognition.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:01:11.428937Z","iopub.execute_input":"2024-12-16T10:01:11.429176Z","iopub.status.idle":"2024-12-16T10:01:12.443152Z","shell.execute_reply.started":"2024-12-16T10:01:11.429151Z","shell.execute_reply":"2024-12-16T10:01:12.441682Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'Japanese-Characters-Recognition' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/Japanese-Characters-Recognition\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras import layers, Model\nfrom data_loader import ClassifierDataset\nfrom parameters import classifier_size, num_classes\nfrom loss_and_metrics import focal_loss\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:01:35.316069Z","iopub.execute_input":"2024-12-16T10:01:35.316397Z","iopub.status.idle":"2024-12-16T10:01:47.947529Z","shell.execute_reply.started":"2024-12-16T10:01:35.316368Z","shell.execute_reply":"2024-12-16T10:01:47.946820Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n\n# data = pd.read_csv(\"/kaggle/input/japanese-classification/classifier.csv\")\n# data['image_urls'] = data['image_urls'].str.replace(\"data\", \"/kaggle/input/japanese-classification/character_images\", regex = False)\n# counts = data['char'].value_counts()\n# valid_values = counts[counts >= 10].index\n# valid_values\n# filtered_rows = data[data['char'].isin(valid_values)]\n# filtered_rows = filtered_rows.drop(\"labels\", axis = 1)\n\n# unique_chars = filtered_rows['char'].unique()\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(unique_chars)\n# mapping =  dict(zip(unique_chars, encoded_labels))\n# filtered_rows['labels'] = filtered_rows['char'].map(mapping)\n# data = filtered_rows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:01:53.524741Z","iopub.execute_input":"2024-12-16T10:01:53.525529Z","iopub.status.idle":"2024-12-16T10:01:55.206057Z","shell.execute_reply.started":"2024-12-16T10:01:53.525496Z","shell.execute_reply":"2024-12-16T10:01:55.205111Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"image_urls = data['image_urls'].to_list()\n\nlabels = data['labels'].to_list()\ntrain_img_urls, test_img_urls, train_labels, test_labels = train_test_split(\n    image_urls, labels, test_size=0.2, random_state=42, stratify=labels\n)\ntrain_classifier = ClassifierDataset(image_urls=train_img_urls, labels=train_labels, batch_size = 64, img_size = (64, 64), augment=True, shuffle=True)\ntest_classifier = ClassifierDataset(image_urls=test_img_urls, labels=test_labels, batch_size = 64,img_size = (64, 64), augment=False, shuffle=False)\ntrain = train_classifier.create_tf_dataset()\ntest = test_classifier.create_tf_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:02:36.306782Z","iopub.execute_input":"2024-12-16T10:02:36.307603Z","iopub.status.idle":"2024-12-16T10:02:39.621782Z","shell.execute_reply.started":"2024-12-16T10:02:36.307568Z","shell.execute_reply":"2024-12-16T10:02:39.620899Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\nfrom tensorflow.keras import mixed_precision\n\n# Set the mixed precision policy to 'mixed_bfloat16'\npolicy = mixed_precision.Policy('mixed_bfloat16')\nmixed_precision.set_global_policy(policy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:02:04.331000Z","iopub.execute_input":"2024-12-16T10:02:04.331613Z","iopub.status.idle":"2024-12-16T10:02:04.336784Z","shell.execute_reply.started":"2024-12-16T10:02:04.331561Z","shell.execute_reply":"2024-12-16T10:02:04.335894Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ncsv = CSVLogger(\n    filename = \"/kaggle/working/Japanese-Characters-Recognition/training_log.csv\", append = True\n)\nearly = EarlyStopping(\n    monitor = 'val_loss', patience = 2\n)\ncheckpoint = ModelCheckpoint(\n    filepath = \"model.keras\",\n    monitor = 'val_loss',\n    verbose = 1,\n    mode = 'min',\n    save_best_only = True,\n    save_weights_only = False,\n    save_freq = 'epoch',\n    initial_value_threshold = 0.9\n)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:02:04.337766Z","iopub.execute_input":"2024-12-16T10:02:04.337992Z","iopub.status.idle":"2024-12-16T10:02:04.349143Z","shell.execute_reply.started":"2024-12-16T10:02:04.337969Z","shell.execute_reply":"2024-12-16T10:02:04.348331Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"batch_size = 64\nlen_train = int(len(train_img_urls) / batch_size)\nlen_test = int(len(test_img_urls) / batch_size)\n\nstrategy = tf.distribute.MirroredStrategy()\ntf.debugging.set_log_device_placement(True)\n\nwith strategy.scope():\n    model = tf.keras.models.load_model(\"/kaggle/working/Japanese-Characters-Recognition/first.keras\")\n    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n    model.compile(loss=my_loss, optimizer=optim, metrics=[\"accuracy\"])\n\nhistory = model.fit(train, epochs=3, validation_data=test, \n                   steps_per_epoch = len_train, validation_steps= len_test, callbacks = [csv, early, checkpoint, reduce_lr])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:20:00.127488Z","iopub.execute_input":"2024-12-16T11:20:00.127847Z","iopub.status.idle":"2024-12-16T15:19:25.581055Z","shell.execute_reply.started":"2024-12-16T11:20:00.127814Z","shell.execute_reply":"2024-12-16T15:19:25.580026Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"2024-12-16 11:20:34.261691: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/cond/else/_744/cond/StatefulPartitionedCall/functional_3_1/dropout_5_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n/tmp/ipykernel_23/1443643313.py:26: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=30, p=0.3),  # Distortions for handwriting\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8458/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 0.6841 - loss: 0.3568\nEpoch 1: val_loss improved from 0.43422 to 0.10215, saving model to model.keras\n\u001b[1m8458/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4781s\u001b[0m 560ms/step - accuracy: 0.6841 - loss: 0.3568 - val_accuracy: 0.8748 - val_loss: 0.1022 - learning_rate: 0.0010\nEpoch 2/3\n\u001b[1m8458/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.8735 - loss: 0.0969\nEpoch 2: val_loss improved from 0.10215 to 0.05897, saving model to model.keras\n\u001b[1m8458/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4763s\u001b[0m 563ms/step - accuracy: 0.8735 - loss: 0.0969 - val_accuracy: 0.9145 - val_loss: 0.0590 - learning_rate: 0.0010\nEpoch 3/3\n\u001b[1m8327/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m59s\u001b[0m 458ms/step - accuracy: 0.9177 - loss: 0.0528 \nEpoch 3: val_loss improved from 0.05897 to 0.04249, saving model to model.keras\n\u001b[1m8458/8458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4783s\u001b[0m 566ms/step - accuracy: 0.9178 - loss: 0.0527 - val_accuracy: 0.9356 - val_loss: 0.0425 - learning_rate: 0.0010\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model.save(\"first.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T15:27:24.403965Z","iopub.execute_input":"2024-12-16T15:27:24.404796Z","iopub.status.idle":"2024-12-16T15:27:25.258203Z","shell.execute_reply.started":"2024-12-16T15:27:24.404760Z","shell.execute_reply":"2024-12-16T15:27:25.257143Z"}},"outputs":[],"execution_count":20}]}